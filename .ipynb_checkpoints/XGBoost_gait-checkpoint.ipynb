{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salembien/[/home/salembien/Bureau/anaconda3]/envs/IA/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#LABIA\n",
    "#source1 = '../data/Gait_Data___Arm_swing.csv'\n",
    "#source2 = '../data/Consensus_Committee_Analytic_Datasets_28OCT21.xlsx'\n",
    "\n",
    "#Local jupyter\n",
    "source2 = \"../Quick_Start/Consensus_Committee_Analytic_Datasets_28OCT21.xlsx\"\n",
    "source1 = \"../Motor___MDS-UPDRS/Gait_Data___Arm_swing.csv\"\n",
    "\n",
    "\n",
    "# import data for a first visualisation\n",
    "data = pd.read_csv(source1)\n",
    "data.head()\n",
    "\n",
    "# df_first = merge of all csv sheets from Analytic Datasets\n",
    "file = source2\n",
    "\n",
    "df1 = pd.read_excel(file,'PD')\n",
    "df2 = pd.read_excel(file, 'HC')\n",
    "df3 = pd.read_excel(file, 'Prodromal')\n",
    "df4 = pd.read_excel(file, 'SWEDD')\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "df_first = df.sort_values(['PATNO'])\n",
    "df_first = df_first.set_index('PATNO')\n",
    "\n",
    "#df_arm file analyzed\n",
    "file_arm = source1\n",
    "df_arm = pd.read_csv(file_arm)\n",
    "\n",
    "# Get the PATNO of the unknown cohort\n",
    "df_na_arm = df_arm.loc[df_arm['COHORT'].isna(),['PATNO']]\n",
    "# Get their cohort\n",
    "df_complete = df_first.loc[df_na_arm['PATNO'],['Cohort']].replace(['Prodromal',\"Parkinson's Disease\"],[1,3])\n",
    "#Replace Nan in df_arm['COHORT']\n",
    "df_arm.loc[df_arm.COHORT.isnull(), 'COHORT'] = list(df_complete['Cohort'])\n",
    "\n",
    "# remplace v8 et V8 par V08 idem V2 v6 V10 v10 v11\n",
    "df_arm[\"EVENT_ID\"].iloc[np.where(df_arm[\"EVENT_ID\"]=='v8')]='V08'\n",
    "df_arm[\"EVENT_ID\"].iloc[np.where(df_arm[\"EVENT_ID\"]=='V8')]='V08'\n",
    "df_arm[\"EVENT_ID\"].iloc[np.where(df_arm[\"EVENT_ID\"]=='V2')]='V02'\n",
    "df_arm[\"EVENT_ID\"].iloc[np.where(df_arm[\"EVENT_ID\"]=='v6')]='V06'\n",
    "df_arm[\"EVENT_ID\"].iloc[np.where(df_arm[\"EVENT_ID\"]=='v10')]='V10'\n",
    "df_arm[\"EVENT_ID\"].iloc[np.where(df_arm[\"EVENT_ID\"]=='v11')]='V11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ère méthode pour combler Nan avec KNN\n",
    "\n",
    "from sklearn.impute import KNNImputer \n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_arm_full = imputer.fit_transform(df_arm.iloc[:,4:])\n",
    "df_arm_full = pd.DataFrame(df_arm_full, columns=df_arm.iloc[:,4:].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Première approche avec initialisation basique qui sert de référence\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy de la prédiction\n",
    "from sklearn import metrics\n",
    "def comp(model, x_test, y_test, title):\n",
    "    pred = model.predict(x_test)\n",
    "    print(title+ ' :')\n",
    "    # Accuracy\n",
    "    print(\"Accuracy : \", metrics.accuracy_score(y_test, pred))\n",
    "    # Matrice de confusion\n",
    "    #conf = metrics.confusion_matrix(y_test, pred)\n",
    "    #normalisation = conf/conf.sum(axis=1)[:, np.newaxis]\n",
    "    #sns.heatmap(normalisation, annot=True, cmap='vlag')\n",
    "    #plt.xticks(np.arange(2)+0.5, ['Parkisons Disease', 'Podromal'], rotation=25)\n",
    "    #plt.yticks(np.arange(2)+0.5, ['Parkisons Disease', 'Podromal'], rotation=0)\n",
    "    #plt.xlabel('Predicted label')\n",
    "    #plt.ylabel('True label')\n",
    "    #plt.title('Matrice de confusion : ')\n",
    "    #plt.show()\n",
    "    # Rapport\n",
    "    print(\"Rapport :\\n{}\".format(metrics.classification_report(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salembien/[/home/salembien/Bureau/anaconda3]/envs/IA/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Base XGBC :\n",
      "Accuracy :  0.6410256410256411\n",
      "Rapport :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.64      0.56        14\n",
      "         3.0       0.76      0.64      0.70        25\n",
      "\n",
      "    accuracy                           0.64        39\n",
      "   macro avg       0.63      0.64      0.63        39\n",
      "weighted avg       0.67      0.64      0.65        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_arm_full, df_arm['COHORT'], test_size=0.2)\n",
    "xgbc = xgb.XGBClassifier()\n",
    "xgbc.fit(x_train, y_train)\n",
    "comp(xgbc, x_test, y_test, 'Base XGBC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Analyse plus fine des paramètres**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1er balayage sur large éventail de sets d'hyperparamètres avec RandomizedSearchCV\n",
    "\n",
    "grille_xgb = { \n",
    "        'learning_rate': [0.05, 0.1, 0.3, 0.7],\n",
    "        'n_estimators':[50, 200, 500, 1000],\n",
    "        'max_depth': [i for i in range(3,20,2)],\n",
    "        'lambda': [1],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.01, 0.1, 0.5, 1],\n",
    "        'subsample': [0.1, 0.5, 1, 5],\n",
    "        'colsample_bytree': [0.05, 0.1, 0.5, 1],\n",
    "        'max_depth': [2, 5, 10, 20]}\n",
    "\n",
    "# Choix aléatoire parmi 4*4*9*1*3*4*4*4*4=110592 combinaisons de paramètres possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salembien/[/home/salembien/Bureau/anaconda3]/envs/IA/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:58:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.5,\n",
       " 'n_estimators': 500,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 20,\n",
       " 'learning_rate': 0.1,\n",
       " 'lambda': 1,\n",
       " 'gamma': 1,\n",
       " 'colsample_bytree': 0.1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Search CV training\n",
    "\n",
    "# 500 combinaisons et K = 5 folds\n",
    "xgbc_random = RandomizedSearchCV(estimator = xgbc, param_distributions = grille_xgb, n_iter = 1000, cv = 5, n_jobs = -1)\n",
    "xgbc_random.fit(x_train, y_train)\n",
    "xgbc_random.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
